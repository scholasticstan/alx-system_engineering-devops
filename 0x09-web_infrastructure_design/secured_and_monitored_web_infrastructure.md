# Explained

# What are firewalls for
Answer: Firewalls are security devices or software applications that act as a barrier between a trusted internal network and an untrusted external network, such as the Internet. Their primary purpose is to monitor and control network traffic, allowing or blocking specific types of data packets based on predetermined security rules.

By enforcing security policies, firewalls help protect networks from unauthorized access, data breaches, malware, and other cyber threats. They play a crucial role in network security architectures, acting as a first line of defense for organizations and individuals by controlling and filtering incoming and outgoing network traffic.

# Why is the traffic served over HTTPS
Answer:Traffic is served over HTTPS (Hypertext Transfer Protocol Secure) to provide a secure and encrypted communication channel between a client (such as a web browser) and a server. 

# What monitoring is used for
Answer: Monitoring is used for various purposes such as:
1. Network Monitoring: Network monitoring involves the continuous observation of network infrastructure, devices, and traffic to ensure their optimal performance, availability, and security. 

2.System Monitoring: System monitoring focuses on monitoring the health, performance, and availability of servers, computers, and other IT systems. It involves monitoring system resource usage (CPU, memory, disk), service availability, and system logs. System monitoring helps identify issues like high resource utilization, crashes, failures, or abnormal system behavior.

3. Application Monitoring: Application monitoring involves tracking the performance, availability, and usage of software applications. It provides insights into application response times, transaction throughput, error rates, and resource utilization. 

4. Security Monitoring: Security monitoring involves the continuous surveillance of systems and networks to detect and respond to security threats. It includes monitoring for intrusion attempts, malware infections, data breaches, and other malicious activities. 

5. Performance Monitoring: Performance monitoring focuses on measuring and analyzing the performance of various components in a system or network. It involves monitoring metrics like response times, latency, throughput, and resource utilization.

6. Log Monitoring: Log monitoring involves the collection, analysis, and interpretation of logs generated by various systems, applications, and devices. It helps in troubleshooting issues, detecting anomalies, and identifying security incidents. Log monitoring can provide valuable insights into system behavior, errors, and user activities.


#How the monitoring tool is collecting data

The mointoring tool used in collecting data is Agent-based Monitoring

# Explain what to do if you want to monitor your web server QPS

1. Choose a Monitoring Solution: Select a suitable monitoring tool from options like Prometheus, Nagios, Zabbix, Datadog, or New Relic.

2. Install and Configure: Set up the monitoring tool on your web server by installing an agent or exporter and following the tool's documentation for configuration.

3. Identify QPS Metric: Determine the metric or performance counter representing QPS based on your web server software, such as mod_status for Apache HTTP Server or stub_status for NGINX.

4. Configure Data Collection: Specify the data source and extraction method for the QPS metric in the monitoring tool's configuration.

5. Set Up Alerting: Configure alerts for exceeding QPS thresholds or detecting anomalies.

6. Visualize and Analyze Data: Utilize the monitoring tool's visualization features to track QPS trends, identify peak usage, and uncover performance issues.

7. Fine-tune and Optimize: Regularly monitor QPS metrics, make adjustments, and optimize server capacity, caching, database queries, and application code to improve performance.

# Why terminating SSL at the load balancer level is an issue

Terminating SSL at the load balancer level can pose issues:

1. End-to-End Encryption: Breaks encryption between load balancer and backend servers, compromising data security.

2. Data Security and Compliance: Violates security and compliance requirements that mandate end-to-end encryption.

3. Loss of Client Authentication: Backend servers lose access to client authentication information.

4. Increased Load Balancer Processing: Adds computational load on the load balancer, affecting performance and scalability.

5. Backend Server Overhead: Makes it difficult to perform certain tasks and monitor SSL-related metrics.

6. Limited Flexibility: Restricts the use of advanced SSL/TLS features at the backend server level.

# Why having only one MySQL server capable of accepting writes is an issue

Having only one writable MySQL server can be problematic due to:

1. Single Point of Failure: Increased risk of downtime and data loss.

2. Limited Scalability: Inability to handle high write traffic efficiently.
Lack of High Availability: No automatic failover mechanism during server unavailability.

3. Data Consistency Challenges: Difficulty in maintaining data consistency in distributed systems.

4. Concurrency and Performance Limitations: Contention and decreased performance during concurrent writes.

5. Scalability and Load Balancing: Inability to distribute write load and ensure consistent performance.

6. Implementing replication, clustering, or sharding can mitigate these issues by providing fault tolerance, scalability, and improved performance.

# Why having servers with all the same components (database, web server and application server) might be a problem

Having servers with all the same components (database, web server, and application server) can lead to issues such as:

1. Lack of separation and troubleshooting difficulties.

2. Limited scalability and inefficient resource allocation.

3. Performance bottlenecks due to resource contention.

4. Reduced fault isolation and increased downtime risk.

5. Challenges with maintenance and upgrades.

6. Restrictions on technology stack and flexibility.

Adopting a modular and distributed architecture mitigates these issues, providing better scalability, fault isolation, performance optimization, and flexibility in managing components.
